# ğŸ—ï¸ RAG Architecture with Akool Streaming Avatar

## ğŸ“‹ **Overview: How RAG Works Here**

The RAG (Retrieval-Augmented Generation) system in this Akool streaming avatar application is **directly integrated** into the frontend application, **NOT using external backend endpoints**. It's a **client-side RAG implementation** that processes documents locally and connects to external AI services for embeddings and LLM responses.

---

## ğŸ—ï¸ **Architecture Overview**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CLIENT-SIDE RAG SYSTEM                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Document      â”‚    â”‚   Embedding     â”‚    â”‚   LLM        â”‚ â”‚
â”‚  â”‚   Processing    â”‚    â”‚   Service       â”‚    â”‚   Service    â”‚ â”‚
â”‚  â”‚   (Local)       â”‚    â”‚   (External)    â”‚    â”‚   (External) â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚           â”‚                       â”‚                       â”‚      â”‚
â”‚           â–¼                       â–¼                       â–¼      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              RAG Processing Pipeline                        â”‚ â”‚
â”‚  â”‚  â€¢ Document Chunking  â€¢ Vector Search  â€¢ Response Gen     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚           â”‚                                                      â”‚
â”‚           â–¼                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              Akool Avatar Integration                       â”‚ â”‚
â”‚  â”‚  â€¢ Voice Message Interception  â€¢ Response Streaming        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ **Core Components**

### **1. Document Processing (Client-Side)**
```typescript
// Location: src/services/enterpriseRAGService.ts
class EnterpriseRAGService {
  // âœ… PDF processing using PDF.js (browser-compatible)
  private async extractTextFromFile(file: File): Promise<string>
  
  // âœ… Document chunking and storage (in-memory)
  private splitTextIntoChunks(text: string): string[]
  
  // âœ… Local document management
  private documents: Map<string, EnterpriseDocument> = new Map()
}
```

### **2. Embedding Service (External API)**
```typescript
// Uses Azure OpenAI or OpenAI for embeddings
private async generateEmbedding(text: string): Promise<number[]> {
  // Azure OpenAI endpoint:
  // ***REMOVED***openai/deployments/text-embedding-3-large/embeddings
  
  // OR OpenAI endpoint:
  // https://api.openai.com/v1/embeddings
}
```

### **3. LLM Service (External API)**
```typescript
// Uses Azure OpenAI or OpenAI for response generation
class LLMService {
  // Azure OpenAI endpoint:
  // ***REMOVED***openai/deployments/gpt-4o/chat/completions
  
  // OR OpenAI endpoint:
  // https://api.openai.com/v1/chat/completions
}
```

### **4. Akool Avatar Integration**
```typescript
// Location: src/hooks/useStreaming.ts
// Intercepts voice messages and routes through RAG
if (from === 'user') {
  // Process through RAG system
  await sendMessageWithRAG(client, text, userId, sessionId);
  return; // Block original message
}
```

---

## ğŸ”„ **Complete Data Flow**

### **Step 1: Document Upload**
```
User uploads PDF â†’ PDF.js extracts text â†’ Document chunked â†’ Embeddings generated â†’ Stored in memory
```

### **Step 2: User Query (Voice/Chat)**
```
User asks question â†’ Voice message intercepted â†’ Query embedding generated â†’ Semantic search â†’ Context retrieved
```

### **Step 3: Response Generation**
```
Context + Query â†’ LLM service â†’ Response generated â†’ Cleaned and formatted â†’ Sent to avatar
```

### **Step 4: Avatar Response**
```
Avatar receives response â†’ Speaks the answer â†’ User hears RAG-generated response
```

---

## ğŸŒ **External Service Connections**

### **âœ… Azure OpenAI Integration**
```bash
# Environment Variables Used:
VITE_AZURE_OPENAI_KEY=***REMOVED***
VITE_AZURE_OPENAI_ENDPOINT=***REMOVED***
VITE_AZURE_GPT4O_DEPLOYMENT=gpt-4o
VITE_AZURE_EMBEDDING_DEPLOYMENT=text-embedding-3-large
VITE_AZURE_API_VERSION=2024-05-01-preview
```

### **âœ… Akool API Integration**
```bash
# Environment Variables Used:
VITE_OPENAPI_HOST=https://openapi.akool.com
VITE_OPENAPI_TOKEN=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
```

### **âœ… Optional: Chroma Cloud (Alternative Vector Store)**
```bash
# Environment Variables Used:
VITE_CHROMA_API_KEY=ck-D3ctzwSTiYLQjjwe15EkEiLBjKzzRg5J8QgVzzrqFQw5
VITE_CHROMA_TENANT=cdf95420-77eb-4b06-a3a2-15eb8db79166
VITE_CHROMA_DATABASE=akooldb
VITE_CHROMA_COLLECTION_NAME=enterprise_documents
```

---

## ğŸ¯ **Key Features**

### **âœ… Client-Side Processing**
- **No backend required** - Everything runs in the browser
- **Document processing** using PDF.js (browser-compatible)
- **In-memory storage** of documents and embeddings
- **Real-time processing** without server round-trips

### **âœ… External AI Services**
- **Azure OpenAI** for embeddings and LLM responses
- **Fallback to OpenAI** if Azure is not configured
- **Akool API** for avatar streaming and voice processing

### **âœ… Voice Integration**
- **Voice message interception** - RAG processes voice input
- **Response streaming** - Avatar speaks RAG-generated answers
- **Message blocking** - Prevents original voice message from reaching avatar

### **âœ… Document Support**
- **PDF processing** with PDF.js
- **Text extraction** and chunking
- **Embedding generation** for semantic search
- **Fallback handling** for processing errors

---

## ğŸ”§ **Configuration Options**

### **RAG Configuration**
```typescript
interface RAGConfig {
  maxChunks: number;           // Max chunks to retrieve (default: 5)
  similarityThreshold: number; // Min similarity score (default: 0.05)
  enableCaching: boolean;      // Enable response caching (default: true)
  cacheExpiry: number;         // Cache expiry in minutes (default: 60)
  maxTokens: number;           // Max tokens in response (default: 2000)
  temperature: number;         // LLM temperature (default: 0.3)
}
```

### **Avatar Mode Configuration**
```typescript
// Mode 1 (Repeat) - Avatar repeats received text (RAG responses)
// Mode 2 (Dialogue) - Avatar generates responses (LLM responses)
VITE_MODE_TYPE=1  // Default to Repeat mode for RAG
```

---

## ğŸš€ **Deployment Architecture**

### **âœ… Frontend-Only Deployment**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Vercel/Netlify/GitHub Pages                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              React Application                              â”‚ â”‚
â”‚  â”‚  â€¢ RAG Processing  â€¢ Document Management  â€¢ Voice Handling â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    External Services                            â”‚
â”‚  â€¢ Azure OpenAI (Embeddings + LLM)  â€¢ Akool API (Avatar)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **âœ… No Backend Required**
- **Static hosting** - Can be deployed to any static hosting service
- **Client-side processing** - All RAG logic runs in the browser
- **External APIs only** - Only connects to Azure OpenAI and Akool APIs

---

## ğŸ¯ **Advantages of This Architecture**

### **âœ… Simplicity**
- **No backend maintenance** - Everything runs in the browser
- **Easy deployment** - Just deploy the React app
- **No server costs** - Only pay for external API usage

### **âœ… Performance**
- **Fast processing** - No server round-trips for document processing
- **Real-time responses** - Direct integration with avatar streaming
- **Efficient caching** - In-memory caching of embeddings and responses

### **âœ… Scalability**
- **Client-side scaling** - Each user has their own processing
- **API-based scaling** - External services handle the heavy lifting
- **Flexible configuration** - Easy to switch between different AI providers

---

## ğŸ” **Summary**

**The RAG system in this Akool streaming avatar application is:**

1. **âœ… Directly Integrated** - No external backend endpoints
2. **âœ… Client-Side Processing** - Runs entirely in the browser
3. **âœ… External AI Services** - Uses Azure OpenAI/OpenAI for embeddings and LLM
4. **âœ… Akool Integration** - Seamlessly integrated with Akool avatar streaming
5. **âœ… Voice-Enabled** - Processes voice input and generates voice responses
6. **âœ… Document-Ready** - Handles PDF uploads and text processing
7. **âœ… Production-Ready** - Can be deployed as a static application

**This architecture provides a complete RAG solution without requiring any backend infrastructure, making it easy to deploy and maintain while providing powerful document-based question answering capabilities through the Akool streaming avatar.**
